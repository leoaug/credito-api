spring:
  config:
    import:
      optional:file:./env.properties,classpath:version.properties
 
  datasource:
    url: ${DATA_SOURCE_URL}${DATA_SOURCE_DB}
    username: ${DATA_SOURCE_USER_NAME}
    password: ${DATA_SOURCE_PASSWORD}
    driver-class-name: org.postgresql.Driver

  jpa:
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        format_sql: true
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    admin:
      auto-create: true
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 5
      properties:
        retry.backoff.ms: 1000
        delivery.timeout.ms: 30000
    consumer:
      group-id: credito-group
      auto-offset-reset: earliest
      enable-auto-commit: false   # recomendado gerenciar manualmente
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # listener (container factory padr√£o)
    listener:
      ack-mode: MANUAL_IMMEDIATE                    # ou BATCH quando usar batch
      # concurrency: 3                            # threads por container
      # poll-timeout: 3000

    # template (KafkaTemplate)
    template:
      default-topic: credito-api
  logging:
   level:
    org.springframework.kafka: INFO
    org.apache.kafka: WARN
    com.seuapp: DEBUG  
                        
  azure:
    servicebus:
      connection-string: ${AZURE_SERVICEBUS_CONNECTION_STRING}
      queue-name: credito-queue
